# =============================================================================
# Production Ingress Configuration
# =============================================================================
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ai-inference
  labels:
    app: ai-inference
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "10m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "60"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - ai-inference.your-domain.com
      secretName: ai-inference-tls
  rules:
    - host: ai-inference.your-domain.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: ai-inference
                port:
                  number: 80
