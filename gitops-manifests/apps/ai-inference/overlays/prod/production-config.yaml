# =============================================================================
# Production Configuration Patches
# =============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-inference
spec:
  replicas: 3
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
    spec:
      containers:
        - name: ai-inference
          env:
            - name: DEBUG
              value: "false"
            - name: LOG_LEVEL
              value: "WARN"
            - name: WORKERS
              value: "8"
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "4Gi"
              cpu: "2000m"
      
      # Production tolerations for dedicated nodes
      tolerations:
        - key: "dedicated"
          operator: "Equal"
          value: "ai-inference"
          effect: "NoSchedule"
      
      # Node selector for production nodes
      nodeSelector:
        workload-type: ai-inference
      
      # Priority class for production workloads
      priorityClassName: high-priority

---
# Production HPA settings
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-inference
spec:
  minReplicas: 3
  maxReplicas: 20
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 70

---
# Production PDB - more strict
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: ai-inference
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: ai-inference
